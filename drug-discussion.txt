The same models did not produce the same result. The first reason is that in the test_train slpit function None value was chosen for random-state parameter which generates new instances of train and test datasets. More over,changing the value of the classifiers parameters affected the output of the code. For instance, changing cross validation number in Top-DT from 5 to 10 significantly imroved the accuracy, recall and precison of the model or in TOP-MLP increacsing the hidden layers improved the predictions by the model.    